#!/usr/bin/env python3
"""
LocalBrain Background Daemon

Runs as a background service (even when Electron app is closed) and handles:
- localbrain:// protocol requests
- Background ingestion tasks
- System tray menu

Usage:
    python src/daemon.py
"""

import sys
import json
import logging
from pathlib import Path
from urllib.parse import urlparse, parse_qs, unquote
from datetime import datetime
from typing import Dict, Optional

from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import uvicorn
from dotenv import load_dotenv

# Load environment
dotenv_path = Path(__file__).parent.parent / '.env'
load_dotenv(dotenv_path)

# Add src to path
sys.path.insert(0, str(Path(__file__).parent))

from agentic_ingest import AgenticIngestionPipeline
from agentic_search import Search
from utils.file_ops import read_file

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/tmp/localbrain-daemon.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('localbrain-daemon')

# FastAPI app
app = FastAPI(title="LocalBrain Background Service")

# Global config
VAULT_PATH = Path.home() / "Documents" / "GitHub" / "localbrain" / "my-vault"
PORT = 8765


@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy", "service": "localbrain-daemon"}


@app.post("/protocol/ingest")
async def handle_ingest(request: Request):
    """
    Handle localbrain://ingest protocol requests.
    
    Expected format:
        localbrain://ingest?text=...&platform=...&timestamp=...&url=...
    
    Query parameters:
        - text (required): Content to ingest
        - platform (optional): Source platform (e.g., "Gmail", "Discord")
        - timestamp (optional): ISO 8601 timestamp
        - url (optional): Source URL
    """
    try:
        # Parse request body
        body = await request.json()
        text = body.get('text', '')
        platform = body.get('platform', 'Manual')
        timestamp = body.get('timestamp', datetime.utcnow().isoformat() + 'Z')
        url = body.get('url')
        
        if not text:
            return JSONResponse(
                status_code=400,
                content={'error': 'Missing required parameter: text'}
            )
        
        logger.info(f"Ingesting content from {platform}")
        logger.info(f"Text preview: {text[:100]}...")
        
        # Build metadata
        # Note: 'quote' is LLM-generated during ingestion
        metadata = {
            'platform': platform,
            'timestamp': timestamp,
            'url': url,
            'quote': None  # Will be auto-generated by ContentAnalyzer
        }
        
        # Run ingestion
        pipeline = AgenticIngestionPipeline(VAULT_PATH)
        result = pipeline.ingest(text, metadata, max_retries=3)
        
        if result['success']:
            logger.info("Ingestion successful")
            return JSONResponse(content={
                'success': True,
                'files_created': result.get('files_created', []),
                'files_modified': result.get('files_modified', []),
                'message': 'Content ingested successfully'
            })
        else:
            logger.error(f"Ingestion failed: {result.get('errors', [])}")
            return JSONResponse(
                status_code=500,
                content={
                    'success': False,
                    'errors': result.get('errors', []),
                    'message': 'Ingestion failed'
                }
            )
    
    except Exception as e:
        logger.exception("Error handling ingest request")
        return JSONResponse(
            status_code=500,
            content={'error': str(e)}
        )


@app.post("/protocol/search")
async def handle_search(request: Request):
    """
    Handle localbrain://search protocol requests.
    
    Natural language search - input any question, get relevant context + answer.
    Uses agentic retrieval (ripgrep + LLM with tools) under the hood.
    
    Expected format:
        localbrain://search?q=What was my Meta offer?
    
    Query parameters:
        - q (required): Natural language search query
    """
    try:
        # Parse request body
        body = await request.json()
        query = body.get('q', body.get('query', ''))  # Support both q and query
        
        if not query:
            return JSONResponse(
                status_code=400,
                content={'error': 'Missing required parameter: q'}
            )
        
        logger.info(f"üîç Search: {query}")
        
        # Run search
        searcher = Search(VAULT_PATH)
        result = searcher.search(query)
        
        if result.get('success'):
            logger.info(f"‚úÖ Search complete: {result.get('total_results', 0)} contexts found")
            return JSONResponse(content={
                'success': True,
                'query': result['query'],
                'contexts': result['contexts'],
                'total_results': result['total_results']
            })
        else:
            logger.error(f"‚ùå Search failed: {result.get('error', 'Unknown error')}")
            return JSONResponse(
                status_code=500,
                content={
                    'success': False,
                    'error': result.get('error', 'Search failed'),
                    'query': query
                }
            )
    
    except Exception as e:
        logger.exception("Error handling search")
        return JSONResponse(
            status_code=500,
            content={'error': str(e)}
        )


@app.get("/file/{filepath:path}")
async def get_file(filepath: str):
    """
    Fetch full file content from vault.
    
    Allows AI apps to dive deeper after getting context chunks from search.
    
    Example:
        GET /file/career/Job%20Search.md
    """
    try:
        file_path = VAULT_PATH / filepath
        
        # Security: ensure file is within vault
        if not file_path.is_relative_to(VAULT_PATH):
            return JSONResponse(
                status_code=403,
                content={'error': 'Access denied: file outside vault'}
            )
        
        if not file_path.exists():
            return JSONResponse(
                status_code=404,
                content={'error': f'File not found: {filepath}'}
            )
        
        # Read file content
        content = read_file(file_path)
        
        # Read citations if available
        json_path = file_path.with_suffix('.json')
        citations = {}
        if json_path.exists():
            import json
            try:
                citations = json.loads(read_file(json_path))
            except:
                pass
        
        # Get file metadata
        stat = file_path.stat()
        
        return JSONResponse(content={
            'path': filepath,
            'content': content,
            'citations': citations,
            'size': stat.st_size,
            'last_modified': stat.st_mtime
        })
        
    except Exception as e:
        logger.exception("Error fetching file")
        return JSONResponse(
            status_code=500,
            content={'error': str(e)}
        )


@app.get("/protocol/parse")
async def parse_protocol_url(url: str):
    """
    Parse a localbrain:// URL and return structured data.
    
    Example:
        /protocol/parse?url=localbrain://ingest?text=hello&platform=Gmail
    """
    try:
        parsed = urlparse(url)
        
        if parsed.scheme != 'localbrain':
            return JSONResponse(
                status_code=400,
                content={'error': 'Invalid protocol scheme (expected localbrain://)'}
            )
        
        command = parsed.netloc
        params = parse_qs(parsed.query)
        
        # Decode parameters
        decoded_params = {
            k: unquote(v[0]) if v else None
            for k, v in params.items()
        }
        
        return {
            'command': command,
            'parameters': decoded_params
        }
    
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={'error': str(e)}
        )


def main():
    """Start the daemon service."""
    logger.info("="*60)
    logger.info("LocalBrain Background Daemon Starting...")
    logger.info("="*60)
    logger.info(f"Vault: {VAULT_PATH}")
    logger.info(f"Port: {PORT}")
    logger.info(f"Protocol: localbrain://")
    logger.info("")
    logger.info("Available commands:")
    logger.info("  localbrain://ingest?text=...&platform=...&timestamp=...&url=...")
    logger.info("")
    logger.info("Service running. Press Ctrl+C to stop.")
    logger.info("="*60)
    
    # Start FastAPI server
    uvicorn.run(
        app,
        host="127.0.0.1",
        port=PORT,
        log_level="info",
        access_log=True
    )


if __name__ == "__main__":
    main()
